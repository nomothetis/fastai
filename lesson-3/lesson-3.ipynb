{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: /home/ubuntu/data/\n",
      "Options:\n",
      "  Testing directory: /home/ubuntu/data/statefarm/test/\n",
      "  Training directory: /home/ubuntu/data/statefarm/train/\n",
      "  Validation directory: /home/ubuntu/data/statefarm/valid/\n",
      "  Preprocess directory: /home/ubuntu/data/statefarm/preprocessed/\n",
      "  Results directory: /home/ubuntu/data/statefarm/results\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os,sys\n",
    "notebook_code_root = os.path.dirname(os.getcwd())\n",
    "data_root = os.path.dirname(notebook_code_root) + '/data/'\n",
    "print(\"Data root: %s\" % data_root)\n",
    "sys.path.insert(0,notebook_code_root)\n",
    "\n",
    "import cutils\n",
    "from cutils import *\n",
    "\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from vgg16 import *\n",
    "\n",
    "opts = NotebookData(data_dir=data_root, sample_mode=False, preprocess=True)\n",
    "print(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the VGG model.\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = vgg.model.layers\n",
    "idx = 0\n",
    "for i in range(len(ls)):\n",
    "    if type(ls[i]) is MaxPooling2D:\n",
    "        idx = i\n",
    "\n",
    "conv_model = Sequential(layers=ls[:(idx+1)])\n",
    "fc_layers = ls[(idx+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(opt):\n",
    "    tf = None\n",
    "    vf = None\n",
    "    tc = None\n",
    "    vc = None\n",
    "    trn_dir = os.path.join(opt.data_root, 'preprocessed', 'conv')\n",
    "    if opt.preprocess:\n",
    "        gen = image.ImageDataGenerator()\n",
    "        img_trn_batches = gen.flow_from_directory(opt.train_dir(),\n",
    "                                                  target_size=(224,224),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=64)\n",
    "        img_val_batches = gen.flow_from_directory(opt.valid_dir(),\n",
    "                                                  target_size=(224,224),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=64)\n",
    "        tc = to_categorical(img_trn_batches.classes)\n",
    "        vc = to_categorical(img_val_batches.classes)\n",
    "        tf = conv_model.predict_generator(img_trn_batches, verbose=1)\n",
    "        vf = conv_model.predict_generator(img_val_batches, verbose=1)\n",
    "        if not os.path.exists(trn_dir):\n",
    "            os.makedirs(trn_dir)\n",
    "        save_array(os.path.join(trn_dir, 'train-dt'), tf)\n",
    "        save_array(os.path.join(trn_dir, 'val-dt'), vf)\n",
    "        save_array(os.path.join(trn_dir, 'train-cl'), tc)\n",
    "        save_array(os.path.join(trn_dir, 'val-cl'), vc)\n",
    "    else:\n",
    "        tf = load_array(os.path.join(trn_dir, 'train-dt'))\n",
    "        vf = load_array(os.path.join(trn_dir, 'val-dt'))\n",
    "        tc = load_array(os.path.join(trn_dir, 'train-cl'))\n",
    "        vc = load_array(os.path.join(trn_dir, 'val-cl'))\n",
    "        \n",
    "    return (tf, vf, tc, vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17622 images belonging to 10 classes.\n",
      "Found 4802 images belonging to 10 classes.\n",
      "276/276 [==============================] - 334s 1s/step\n",
      "76/76 [==============================] - 92s 1s/step\n"
     ]
    }
   ],
   "source": [
    "trn_features, val_features, img_trn_classes, img_val_classes = get_data(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rand_training(trn, img):\n",
    "    zipped_trn = zip(trn, img)\n",
    "    np.random.shuffle(zipped_trn)\n",
    "    trn_data = np.stack([data for data, cl in zipped_trn], axis=0)\n",
    "    trn_cls = np.stack([cl for data, cl in zipped_trn], axis=0)\n",
    "    return trn_data, trn_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new model with only dense layers.\n",
    "fc_model = Sequential([\n",
    "     # Input shape is shape of the conv result.\n",
    "     Reshape((25088,), input_shape=(512, 7, 7,)),\n",
    "     Dense(256, activation=\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.2),\n",
    "     Dense(128, activation='relu'),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.3),\n",
    "     Dense(128, activation='relu'),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.5),\n",
    "     Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.compile(optimizer=Adam(lr=0.000001),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 269us/step - loss: 0.1137 - acc: 0.9785 - val_loss: 1.4265 - val_acc: 0.5523\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.1113 - acc: 0.9795 - val_loss: 1.4296 - val_acc: 0.5512\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.1111 - acc: 0.9780 - val_loss: 1.4124 - val_acc: 0.5546\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.1050 - acc: 0.9814 - val_loss: 1.4116 - val_acc: 0.5552\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.1062 - acc: 0.9801 - val_loss: 1.4128 - val_acc: 0.5575\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0991 - acc: 0.9818 - val_loss: 1.4282 - val_acc: 0.5504\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 263us/step - loss: 0.0977 - acc: 0.9825 - val_loss: 1.4289 - val_acc: 0.5554\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 262us/step - loss: 0.0962 - acc: 0.9850 - val_loss: 1.4191 - val_acc: 0.5541\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0909 - acc: 0.9834 - val_loss: 1.4159 - val_acc: 0.5616\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0889 - acc: 0.9856 - val_loss: 1.4157 - val_acc: 0.5571\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0898 - acc: 0.9843 - val_loss: 1.4177 - val_acc: 0.5583\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0880 - acc: 0.9852 - val_loss: 1.4183 - val_acc: 0.5558\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0878 - acc: 0.9845 - val_loss: 1.4074 - val_acc: 0.5587\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0854 - acc: 0.9845 - val_loss: 1.4026 - val_acc: 0.5587\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0825 - acc: 0.9858 - val_loss: 1.4047 - val_acc: 0.5594\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0794 - acc: 0.9864 - val_loss: 1.3863 - val_acc: 0.5656\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0766 - acc: 0.9883 - val_loss: 1.3854 - val_acc: 0.5662\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 263us/step - loss: 0.0763 - acc: 0.9871 - val_loss: 1.3920 - val_acc: 0.5656\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0763 - acc: 0.9871 - val_loss: 1.3956 - val_acc: 0.5637\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0732 - acc: 0.9884 - val_loss: 1.3915 - val_acc: 0.5687\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0686 - acc: 0.9894 - val_loss: 1.3943 - val_acc: 0.5641\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0709 - acc: 0.9879 - val_loss: 1.3874 - val_acc: 0.5685\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0654 - acc: 0.9902 - val_loss: 1.3840 - val_acc: 0.5725\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0660 - acc: 0.9895 - val_loss: 1.3839 - val_acc: 0.5748\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0654 - acc: 0.9901 - val_loss: 1.3756 - val_acc: 0.5818\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0624 - acc: 0.9914 - val_loss: 1.3683 - val_acc: 0.5804\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0634 - acc: 0.9908 - val_loss: 1.3761 - val_acc: 0.5721\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0606 - acc: 0.9908 - val_loss: 1.3788 - val_acc: 0.5727\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 264us/step - loss: 0.0616 - acc: 0.9899 - val_loss: 1.3734 - val_acc: 0.5741\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0607 - acc: 0.9903 - val_loss: 1.3859 - val_acc: 0.5652\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0581 - acc: 0.9911 - val_loss: 1.3836 - val_acc: 0.5687\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0572 - acc: 0.9918 - val_loss: 1.3878 - val_acc: 0.5737\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0556 - acc: 0.9927 - val_loss: 1.3714 - val_acc: 0.5727\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0553 - acc: 0.9930 - val_loss: 1.3669 - val_acc: 0.5754\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0528 - acc: 0.9935 - val_loss: 1.3621 - val_acc: 0.5787\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0539 - acc: 0.9917 - val_loss: 1.3648 - val_acc: 0.5810\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0525 - acc: 0.9923 - val_loss: 1.3725 - val_acc: 0.5733\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0499 - acc: 0.9932 - val_loss: 1.3658 - val_acc: 0.5827\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0507 - acc: 0.9926 - val_loss: 1.3650 - val_acc: 0.5816\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 263us/step - loss: 0.0496 - acc: 0.9925 - val_loss: 1.3745 - val_acc: 0.5791\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0493 - acc: 0.9931 - val_loss: 1.3745 - val_acc: 0.5814\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0453 - acc: 0.9941 - val_loss: 1.3706 - val_acc: 0.5852\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0462 - acc: 0.9936 - val_loss: 1.3674 - val_acc: 0.5812\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0446 - acc: 0.9938 - val_loss: 1.3646 - val_acc: 0.5845\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0450 - acc: 0.9938 - val_loss: 1.3578 - val_acc: 0.5881\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0453 - acc: 0.9940 - val_loss: 1.3581 - val_acc: 0.5891\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0434 - acc: 0.9939 - val_loss: 1.3713 - val_acc: 0.5862\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0432 - acc: 0.9942 - val_loss: 1.3743 - val_acc: 0.5854\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0425 - acc: 0.9946 - val_loss: 1.3853 - val_acc: 0.5829\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0416 - acc: 0.9947 - val_loss: 1.3773 - val_acc: 0.5816\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 264us/step - loss: 0.0407 - acc: 0.9949 - val_loss: 1.3597 - val_acc: 0.5879\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 262us/step - loss: 0.0395 - acc: 0.9947 - val_loss: 1.3693 - val_acc: 0.5818\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 262us/step - loss: 0.0384 - acc: 0.9953 - val_loss: 1.3700 - val_acc: 0.5866\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0387 - acc: 0.9951 - val_loss: 1.3758 - val_acc: 0.5862\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0392 - acc: 0.9947 - val_loss: 1.3704 - val_acc: 0.5833\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0358 - acc: 0.9961 - val_loss: 1.3874 - val_acc: 0.5783\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0364 - acc: 0.9956 - val_loss: 1.3737 - val_acc: 0.5833\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0373 - acc: 0.9955 - val_loss: 1.3801 - val_acc: 0.5854\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0328 - acc: 0.9965 - val_loss: 1.3694 - val_acc: 0.5893\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0351 - acc: 0.9956 - val_loss: 1.3770 - val_acc: 0.5866\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0346 - acc: 0.9956 - val_loss: 1.3756 - val_acc: 0.5898\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 264us/step - loss: 0.0346 - acc: 0.9954 - val_loss: 1.3663 - val_acc: 0.5902\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0332 - acc: 0.9961 - val_loss: 1.3446 - val_acc: 0.6004\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0323 - acc: 0.9960 - val_loss: 1.3532 - val_acc: 0.5916\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0333 - acc: 0.9956 - val_loss: 1.3531 - val_acc: 0.5931\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0326 - acc: 0.9959 - val_loss: 1.3578 - val_acc: 0.5879\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0308 - acc: 0.9963 - val_loss: 1.3652 - val_acc: 0.5923\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0314 - acc: 0.9958 - val_loss: 1.3557 - val_acc: 0.5970\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0302 - acc: 0.9961 - val_loss: 1.3652 - val_acc: 0.5902\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0298 - acc: 0.9972 - val_loss: 1.3738 - val_acc: 0.5920\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0291 - acc: 0.9969 - val_loss: 1.3737 - val_acc: 0.5910\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0281 - acc: 0.9969 - val_loss: 1.3690 - val_acc: 0.5920\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 263us/step - loss: 0.0290 - acc: 0.9968 - val_loss: 1.3684 - val_acc: 0.5923\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0270 - acc: 0.9982 - val_loss: 1.3483 - val_acc: 0.5981\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0281 - acc: 0.9965 - val_loss: 1.3567 - val_acc: 0.5985\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0265 - acc: 0.9975 - val_loss: 1.3512 - val_acc: 0.5973\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0261 - acc: 0.9974 - val_loss: 1.3465 - val_acc: 0.6035\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0263 - acc: 0.9973 - val_loss: 1.3499 - val_acc: 0.6031\n",
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0245 - acc: 0.9976 - val_loss: 1.3671 - val_acc: 0.5937\n",
      "Epoch 2/2\n",
      "17622/17622 [==============================] - 5s 261us/step - loss: 0.0243 - acc: 0.9979 - val_loss: 1.3604 - val_acc: 0.5989\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    training_data, training_classes = rand_training(trn_features, img_trn_classes)\n",
    "    fc_model.fit(x=training_data,\n",
    "                 y=training_classes,\n",
    "                 batch_size=32,\n",
    "                 validation_data=(val_features,img_val_classes),\n",
    "                 epochs=2,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch0\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch1\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch2\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch3\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch4\n",
      "10000/10000 [==============================] - 1s 112us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch5\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch6\n",
      "10000/10000 [==============================] - 1s 112us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch7\n",
      "9726/9726 [==============================] - 1s 111us/step\n",
      "Saved predictions to: /home/ubuntu/data/statefarm/results/v1/preds.dat\n",
      "Saved filenames to: /home/ubuntu/data/statefarm/results/v1/filenames.dat\n"
     ]
    }
   ],
   "source": [
    "process_model(fc_model, opts, 'v1', sub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/lesson-3/submission.csv"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
