{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: /home/ubuntu/data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5103 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:1E.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options:\n",
      "  Testing directory: /home/ubuntu/data/statefarm/test/\n",
      "  Training directory: /home/ubuntu/data/statefarm/train/\n",
      "  Validation directory: /home/ubuntu/data/statefarm/valid/\n",
      "  Preprocess directory: /home/ubuntu/data/statefarm/preprocessed/\n",
      "  Results directory: /home/ubuntu/data/statefarm/results\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os,sys\n",
    "notebook_code_root = os.path.dirname(os.getcwd())\n",
    "data_root = os.path.dirname(notebook_code_root) + '/data/'\n",
    "print(\"Data root: %s\" % data_root)\n",
    "sys.path.insert(0,notebook_code_root)\n",
    "\n",
    "import cutils\n",
    "from cutils import *\n",
    "\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import math\n",
    "\n",
    "from vgg16 import *\n",
    "\n",
    "opts = NotebookData(data_dir=data_root, sample_mode=False, preprocess=False)\n",
    "print(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the VGG model.\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = vgg.model.layers\n",
    "idx = 0\n",
    "for i in range(len(ls)):\n",
    "    if type(ls[i]) is MaxPooling2D:\n",
    "        idx = i\n",
    "\n",
    "conv_model = Sequential(layers=ls[:(idx+1)])\n",
    "fc_layers = ls[(idx+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(opt):\n",
    "    tf = None\n",
    "    vf = None\n",
    "    tc = None\n",
    "    vc = None\n",
    "    trn_dir = os.path.join(opt.data_root, 'preprocessed', 'conv')\n",
    "    tsize = (224,224)\n",
    "    cmode = 'categorical'\n",
    "    if opt.preprocess:\n",
    "        # Create default values.\n",
    "        gen = image.ImageDataGenerator()\n",
    "        img_trn_batches = gen.flow_from_directory(opt.train_dir(),\n",
    "                                                  target_size=tsize,\n",
    "                                                  class_mode=cmode,\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=64)\n",
    "        img_val_batches = gen.flow_from_directory(opt.valid_dir(),\n",
    "                                                  target_size=tsize,\n",
    "                                                  class_mode=cmode,\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=64)\n",
    "        tc = to_categorical(img_trn_batches.classes)\n",
    "        vc = to_categorical(img_val_batches.classes)\n",
    "        tf_d = conv_model.predict_generator(img_trn_batches, verbose=1)\n",
    "        vf = conv_model.predict_generator(img_val_batches, verbose=1)\n",
    "        if not os.path.exists(trn_dir):\n",
    "            os.makedirs(trn_dir)\n",
    "        save_array(os.path.join(trn_dir, 'train-d-dt'), tf_d)\n",
    "        save_array(os.path.join(trn_dir, 'val-dt'), vf)\n",
    "        save_array(os.path.join(trn_dir, 'train-cl'), tc)\n",
    "        save_array(os.path.join(trn_dir, 'val-cl'), vc)\n",
    "        \n",
    "        # Create transformed values.\n",
    "        gen_t = image.ImageDataGenerator(rotation_range=15,\n",
    "                                         width_shift_range=0.1,\n",
    "                                         height_shift_range=0.1,\n",
    "                                         shear_range=0.16)\n",
    "        img_trn_batches_t = gen_t.flow_from_directory(opt.train_dir(),\n",
    "                                                       target_size=tsize,\n",
    "                                                       class_mode = cmode,\n",
    "                                                       shuffle=False,\n",
    "                                                       batch_size=64)\n",
    "        tf_t = conv_model.predict_generator(img_trn_batches_t,\n",
    "                                            steps=int(math.ceil(img_trn_batches_t.n / 64.0)) * 5,\n",
    "                                            verbose=1)\n",
    "        save_array(os.path.join(trn_dir, 'train-t-dt'), tf_t)\n",
    "        tf = np.concatenate([tf_d, tf_t])\n",
    "        tc = np.concatenate([tc] * 6)\n",
    "        if tf.shape[0] != tc.shape[0]:\n",
    "            raise ValueError\n",
    "        \n",
    "    else:\n",
    "        tf_d = load_array(os.path.join(trn_dir, 'train-d-dt'))\n",
    "        tf_t = load_array(os.path.join(trn_dir, 'train-t-dt'))\n",
    "        vf = load_array(os.path.join(trn_dir, 'val-dt'))\n",
    "        tc = load_array(os.path.join(trn_dir, 'train-cl'))\n",
    "        vc = load_array(os.path.join(trn_dir, 'val-cl'))\n",
    "        tf = np.concatenate([tf_d, tf_t])\n",
    "        tc = np.concatenate([tc] * 6)\n",
    "        \n",
    "    return (tf, vf, tc, vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_features, val_features, img_trn_classes, img_val_classes = get_data(opts)\n",
    "zipped_trn = zip(trn_features, img_trn_classes)\n",
    "trn_features = None\n",
    "img_trn_classes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rand_training(zipped_trn):\n",
    "    np.random.shuffle(zipped_trn)\n",
    "    trn_data = np.stack([data for data, cl in zipped_trn], axis=0)\n",
    "    trn_cls = np.stack([cl for data, cl in zipped_trn], axis=0)\n",
    "    return trn_data, trn_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new model with only dense layers.\n",
    "fc_model = Sequential([\n",
    "     # Input shape is shape of the conv result.\n",
    "     Reshape((25088,), input_shape=(512, 7, 7,)),\n",
    "     Dense(10, activation=\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.15),\n",
    "     Dense(256, activation=\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.6),\n",
    "     Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.compile(optimizer=Adam(lr=0.0001),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "Train on 115056 samples, validate on 3248 samples\n",
      "Epoch 1/5\n",
      "115056/115056 [==============================] - 7s 62us/step - loss: 1.8863 - acc: 0.3870 - val_loss: 1.2296 - val_acc: 0.5379\n",
      "Epoch 2/5\n",
      "115056/115056 [==============================] - 7s 62us/step - loss: 0.7529 - acc: 0.7329 - val_loss: 0.9664 - val_acc: 0.6576\n",
      "Epoch 3/5\n",
      "115056/115056 [==============================] - 7s 62us/step - loss: 0.5036 - acc: 0.8180 - val_loss: 0.9009 - val_acc: 0.6890\n",
      "Epoch 4/5\n",
      "115056/115056 [==============================] - 7s 62us/step - loss: 0.3966 - acc: 0.8528 - val_loss: 0.9935 - val_acc: 0.6820\n",
      "Epoch 5/5\n",
      "115056/115056 [==============================] - 7s 62us/step - loss: 0.3377 - acc: 0.8723 - val_loss: 0.9878 - val_acc: 0.6780\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print('\\nIteration %d' % (i+1))\n",
    "    training_data, training_classes = rand_training(zipped_trn)\n",
    "    fc_model.fit(x=training_data,\n",
    "                 y=training_classes,\n",
    "                 batch_size=256,\n",
    "                 validation_data=(val_features,img_val_classes),\n",
    "                 epochs=5,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch0\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch1\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch2\n"
     ]
    }
   ],
   "source": [
    "process_model(fc_model, opts, 'v1', sub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/lesson-3/submission.csv"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
