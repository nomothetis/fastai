{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: /home/ubuntu/data/\n",
      "Options:\n",
      "  Testing directory: /home/ubuntu/data/statefarm/test/\n",
      "  Training directory: /home/ubuntu/data/statefarm/train/\n",
      "  Validation directory: /home/ubuntu/data/statefarm/valid/\n",
      "  Preprocess directory: /home/ubuntu/data/statefarm/preprocessed/\n",
      "  Results directory: /home/ubuntu/data/statefarm/results\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os,sys\n",
    "notebook_code_root = os.path.dirname(os.getcwd())\n",
    "data_root = os.path.dirname(notebook_code_root) + '/data/'\n",
    "print(\"Data root: %s\" % data_root)\n",
    "sys.path.insert(0,notebook_code_root)\n",
    "\n",
    "import cutils\n",
    "from cutils import *\n",
    "\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from vgg16 import *\n",
    "\n",
    "opts = NotebookData(data_dir=data_root, sample_mode=False, preprocess=True)\n",
    "print(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the VGG model.\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = vgg.model.layers\n",
    "idx = 0\n",
    "for i in range(len(ls)):\n",
    "    if type(ls[i]) is MaxPooling2D:\n",
    "        idx = i\n",
    "\n",
    "conv_model = Sequential(layers=ls[:(idx+1)])\n",
    "fc_layers = ls[(idx+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(opt):\n",
    "    tf = None\n",
    "    vf = None\n",
    "    tc = None\n",
    "    vc = None\n",
    "    trn_dir = os.path.join(opt.data_root, 'preprocessed', 'conv')\n",
    "    if opt.preprocess:\n",
    "        gen = image.ImageDataGenerator()\n",
    "        img_trn_batches = gen.flow_from_directory(opt.train_dir(),\n",
    "                                                  target_size=(224,224),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=64)\n",
    "        img_val_batches = gen.flow_from_directory(opt.valid_dir(),\n",
    "                                                  target_size=(224,224),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=64)\n",
    "        tc = to_categorical(img_trn_batches.classes)\n",
    "        vc = to_categorical(img_val_batches.classes)\n",
    "        tf = conv_model.predict_generator(img_trn_batches, verbose=1)\n",
    "        vf = conv_model.predict_generator(img_val_batches, verbose=1)\n",
    "        if not os.path.exists(trn_dir):\n",
    "            os.makedirs(trn_dir)\n",
    "        save_array(os.path.join(trn_dir, 'train-dt'), tf)\n",
    "        save_array(os.path.join(trn_dir, 'val-dt'), vf)\n",
    "        save_array(os.path.join(trn_dir, 'train-cl'), tc)\n",
    "        save_array(os.path.join(trn_dir, 'val-cl'), vc)\n",
    "    else:\n",
    "        tf = load_array(os.path.join(trn_dir, 'train-dt'))\n",
    "        vf = load_array(os.path.join(trn_dir, 'val-dt'))\n",
    "        tc = load_array(os.path.join(trn_dir, 'train-cl'))\n",
    "        vc = load_array(os.path.join(trn_dir, 'val-cl'))\n",
    "        \n",
    "    return (tf, vf, tc, vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17622 images belonging to 10 classes.\n",
      "Found 4802 images belonging to 10 classes.\n",
      "276/276 [==============================] - 334s 1s/step\n",
      "76/76 [==============================] - 92s 1s/step\n"
     ]
    }
   ],
   "source": [
    "trn_features, val_features, img_trn_classes, img_val_classes = get_data(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rand_training(trn, img):\n",
    "    zipped_trn = zip(trn, img)\n",
    "    np.random.shuffle(zipped_trn)\n",
    "    trn_data = np.stack([data for data, cl in zipped_trn], axis=0)\n",
    "    trn_cls = np.stack([cl for data, cl in zipped_trn], axis=0)\n",
    "    return trn_data, trn_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new model with only dense layers.\n",
    "fc_model = Sequential([\n",
    "     # Input shape is shape of the conv result.\n",
    "     Reshape((25088,), input_shape=(512, 7, 7,)),\n",
    "     Dense(256, activation=\"relu\"),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.2),\n",
    "     Dense(128, activation='relu'),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.3),\n",
    "     Dense(128, activation='relu'),\n",
    "     BatchNormalization(),\n",
    "     Dropout(0.5),\n",
    "     Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.compile(optimizer=Adam(lr=0.000001),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17622 samples, validate on 4802 samples\n",
      "Epoch 1/2\n",
      "17622/17622 [==============================] - 5s 269us/step - loss: 0.1137 - acc: 0.9785 - val_loss: 1.4265 - val_acc: 0.5523\n",
      "Epoch 2/2\n",
      " 9664/17622 [===============>..............] - ETA: 1s - loss: 0.1084 - acc: 0.9802"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    training_data, training_classes = rand_training(trn_features, img_trn_classes)\n",
    "    fc_model.fit(x=training_data,\n",
    "                 y=training_classes,\n",
    "                 batch_size=32,\n",
    "                 validation_data=(val_features,img_val_classes),\n",
    "                 epochs=2,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch0\n",
      "10000/10000 [==============================] - 1s 124us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch1\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch2\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch3\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch4\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch5\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch6\n",
      "10000/10000 [==============================] - 1s 108us/step\n",
      "Predicting batch at /home/ubuntu/data/statefarm/preprocessed//test/batch7\n",
      "9726/9726 [==============================] - 1s 108us/step\n",
      "Saved predictions to: /home/ubuntu/data/statefarm/results/v1/preds.dat\n",
      "Saved filenames to: /home/ubuntu/data/statefarm/results/v1/filenames.dat\n"
     ]
    }
   ],
   "source": [
    "process_model(fc_model, opts, 'v1', sub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/lesson-3/submission.csv"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
